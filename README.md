# Chinese-llama3-fastdemo
## å†…å®¹å¯¼å¼•
| ç« èŠ‚                                  | æè¿°                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| [æ¨¡å‹ç®€ä»‹](#ä¸€ã€æ¨¡å‹ç®€ä»‹) | ç®€è¦ä»‹ç»æœ¬é¡¹ç›®ç›¸å…³æ¨¡å‹çš„æŠ€æœ¯ç‰¹ç‚¹ |
| [æ¨¡å‹ä¸‹è½½](#äºŒã€æ¨¡å‹ä¸‹è½½)        | ä¸­æ–‡Llama-3å¤§æ¨¡å‹ä¸‹è½½åœ°å€ |
| [æ¨ç†ä¸éƒ¨ç½²](#ä¸‰ã€æ¨ç†ä¸éƒ¨ç½²) | ä»‹ç»äº†å¦‚ä½•å¯¹æ¨¡å‹è¿›è¡Œé‡åŒ–å¹¶ä½¿ç”¨ä¸ªäººç”µè„‘éƒ¨ç½²å¹¶ä½“éªŒå¤§æ¨¡å‹ |
| [è®­ç»ƒä¸ç²¾è°ƒ](#å››ã€è®­ç»ƒä¸ç²¾è°ƒ) | ä»‹ç»äº†å¦‚ä½•è®­ç»ƒå’Œç²¾è°ƒä¸­æ–‡Llama-3å¤§æ¨¡å‹ |
| [å…è´£å£°æ˜](#äº”ã€å…è´£å£°æ˜) | ç›¸å…³å…è´£å£°æ˜ |

# ä¸€ã€æ¨¡å‹ç®€ä»‹

æœ¬é¡¹ç›®åŸºäºMetaæœ€æ–°å‘å¸ƒçš„æ–°ä¸€ä»£å¼€æºå¤§æ¨¡å‹Llama-3å¼€å‘ï¼Œæ˜¯Chinese-LLaMA-Alpacaå¼€æºå¤§æ¨¡å‹ç›¸å…³ç³»åˆ—é¡¹ç›®çš„ç¬¬ä¸‰æœŸã€‚é¡¹ç›®å¼€æºçš„ä¸­æ–‡Llama-3åŸºåº§æ¨¡å‹å’Œä¸­æ–‡Llama-3-InstructæŒ‡ä»¤ç²¾è°ƒå¤§æ¨¡å‹åœ¨åŸç‰ˆLlama-3çš„åŸºç¡€ä¸Šä½¿ç”¨äº†å¤§è§„æ¨¡ä¸­æ–‡æ•°æ®è¿›è¡Œå¢é‡é¢„è®­ç»ƒï¼Œå¹¶ä¸”ä½¿ç”¨ç²¾é€‰æŒ‡ä»¤æ•°æ®è¿›è¡Œç²¾è°ƒï¼Œè¿›ä¸€æ­¥æå‡äº†ä¸­æ–‡åŸºç¡€è¯­ä¹‰å’ŒæŒ‡ä»¤ç†è§£èƒ½åŠ›ï¼Œç›¸æ¯”äºŒä»£ç›¸å…³æ¨¡å‹è·å¾—äº†æ˜¾è‘—æ€§èƒ½æå‡ã€‚

# äºŒã€æ¨¡å‹ä¸‹è½½
### æ¨¡å‹é€‰æ‹©æŒ‡å¼•

ä»¥ä¸‹æ˜¯æœ¬é¡¹ç›®çš„æ¨¡å‹å¯¹æ¯”ä»¥åŠå»ºè®®ä½¿ç”¨åœºæ™¯ã€‚**å¦‚éœ€èŠå¤©äº¤äº’ï¼Œè¯·é€‰æ‹©Instructç‰ˆã€‚**

| å¯¹æ¯”é¡¹                | Llama-3-Chinese-8B             | Llama-3-Chinese-8B-Instruct |
| :-------------------- | :----------------------------------------------------: | :----------------------------------------------------------: |
| æ¨¡å‹ç±»å‹ | åŸºåº§æ¨¡å‹ | æŒ‡ä»¤/Chatæ¨¡å‹ï¼ˆç±»ChatGPTï¼‰ |
| æ¨¡å‹å¤§å° | 8B | 8B |
| è®­ç»ƒç±»å‹     | Causal-LM (CLM)           | æŒ‡ä»¤ç²¾è°ƒ                                                     |
| è®­ç»ƒæ–¹å¼ | LoRA + å…¨é‡emb/lm-head | LoRA + å…¨é‡emb/lm-head |
| åˆå§‹åŒ–æ¨¡å‹ | [åŸç‰ˆMeta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B) | v1: Llama-3-Chinese-8B<br/>v2: [åŸç‰ˆMeta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) |
| è®­ç»ƒè¯­æ–™ | æ— æ ‡æ³¨é€šç”¨è¯­æ–™ï¼ˆçº¦120GBï¼‰ | æœ‰æ ‡æ³¨æŒ‡ä»¤æ•°æ®ï¼ˆçº¦500ä¸‡æ¡ï¼‰ |
| è¯è¡¨å¤§å° | åŸç‰ˆè¯è¡¨ï¼ˆ128,256ï¼‰ | åŸç‰ˆè¯è¡¨ï¼ˆ128,256ï¼‰ |
| æ”¯æŒä¸Šä¸‹æ–‡é•¿åº¦ | 8K | 8K |
| è¾“å…¥æ¨¡æ¿              | ä¸éœ€è¦                                                 | éœ€è¦å¥—ç”¨Llama-3-Instructæ¨¡æ¿ |
| é€‚ç”¨åœºæ™¯            | æ–‡æœ¬ç»­å†™ï¼šç»™å®šä¸Šæ–‡ï¼Œè®©æ¨¡å‹ç”Ÿæˆä¸‹æ–‡            | æŒ‡ä»¤ç†è§£ï¼šé—®ç­”ã€å†™ä½œã€èŠå¤©ã€äº¤äº’ç­‰ |

### ä¸‹è½½åœ°å€

| æ¨¡å‹åç§°                  |                    å®Œæ•´ç‰ˆ                    |                    LoRAç‰ˆ                    |                    GGUFç‰ˆ                    |
| :------------------------ | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| **Llama-3-Chinese-8B-Instruct-v2**<br/>(æŒ‡ä»¤æ¨¡å‹) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2)<br/>[[wisemodel]](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2-lora)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-lora)<br/>[[wisemodel]](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-lora) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2-gguf)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-gguf) |
| **Llama-3-Chinese-8B-Instruct**<br/>(æŒ‡ä»¤æ¨¡å‹) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct)<br/>[[wisemodel]](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-lora)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-lora)<br/>[[wisemodel]](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-lora) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-gguf)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-gguf) |
| **Llama-3-Chinese-8B**<br/>(åŸºåº§æ¨¡å‹) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b)<br/>[[wisemodel]](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b-lora)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-lora)<br/>[[wisemodel]](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-lora) | [[ğŸ¤—Hugging Face]](https://huggingface.co/hfl/llama-3-chinese-8b-gguf)<br/> [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-gguf) |

æ¨¡å‹ç±»å‹è¯´æ˜ï¼š

- **å®Œæ•´æ¨¡å‹**ï¼šå¯ç›´æ¥ç”¨äºè®­ç»ƒå’Œæ¨ç†ï¼Œæ— éœ€å…¶ä»–åˆå¹¶æ­¥éª¤
- **LoRAæ¨¡å‹**ï¼šéœ€è¦ä¸åŸºæ¨¡å‹åˆå¹¶å¹¶æ‰èƒ½è½¬ä¸ºå®Œæ•´ç‰ˆæ¨¡å‹ï¼Œåˆå¹¶æ–¹æ³•ï¼š[**ğŸ’» æ¨¡å‹åˆå¹¶æ­¥éª¤**](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/model_conversion_zh)
  - v1åŸºæ¨¡å‹ï¼šåŸç‰ˆ[Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)
  - v2åŸºæ¨¡å‹ï¼šåŸç‰ˆ[Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
- **GGUFæ¨¡å‹**ï¼š[llama.cpp](https://github.com/ggerganov/llama.cpp)æ¨å‡ºçš„é‡åŒ–æ ¼å¼ï¼Œé€‚é…ollamaç­‰å¸¸è§æ¨ç†å·¥å…·ï¼Œæ¨èåªéœ€è¦åšæ¨ç†éƒ¨ç½²çš„ç”¨æˆ·ä¸‹è½½ï¼›æ¨¡å‹ååç¼€ä¸º`-im`è¡¨ç¤ºä½¿ç”¨äº†importance matrixè¿›è¡Œé‡åŒ–ï¼Œé€šå¸¸å…·æœ‰æ›´ä½çš„PPLï¼Œå»ºè®®ä½¿ç”¨ï¼ˆç”¨æ³•ä¸å¸¸è§„ç‰ˆç›¸åŒï¼‰
> [!NOTE]
> è‹¥æ— æ³•è®¿é—®HFï¼Œå¯è€ƒè™‘ä¸€äº›é•œåƒç«™ç‚¹ï¼ˆå¦‚[hf-mirror.com](hf-mirror.com)ï¼‰ï¼Œå…·ä½“æ–¹æ³•è¯·è‡ªè¡ŒæŸ¥æ‰¾è§£å†³ã€‚

# ä¸‰ã€æ¨ç†ä¸éƒ¨ç½²

## 3.1 ä½¿ç”¨transformersè¿›è¡Œæ¨ç†
æˆ‘ä»¬æä¾›äº†å‘½ä»¤è¡Œæ–¹å¼ä½¿ç”¨åŸç”ŸğŸ¤—transformersè¿›è¡Œæ¨ç†ã€‚ä¸‹é¢ä»¥åŠ è½½Llama-3-Chinese-Instructæ¨¡å‹ä¸ºä¾‹è¯´æ˜å¯åŠ¨æ–¹å¼ã€‚
ä¸‹è½½å®Œæ•´ç‰ˆæƒé‡ä¹‹åï¼ŒæŒ‰ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è„šæœ¬ã€‚
```
python scripts/inference/inference_hf.py \
    --base_model path_to_llama3_chinese_instruct_hf_dir \
    --with_prompt \
    --interactive
```

#### ä½¿ç”¨vLLMè¿›è¡Œæ¨ç†åŠ é€Ÿ
å¯ä»¥ä½¿ç”¨vLLMä½œä¸ºLLMåç«¯è¿›è¡Œæ¨ç†ï¼Œéœ€è¦é¢å¤–å®‰è£…vLLMåº“ã€‚
```
pip install vllm
```
åªéœ€åœ¨åŸæœ¬çš„å‘½ä»¤è¡Œä¸Šæ·»åŠ `--use_vllm`å‚æ•°:
```
python scripts/inference/inference_hf.py \
    --base_model path_to_llama3_chinese_instruct_hf_dir \
    --with_prompt \
    --interactive \
    --use_vllm
```
#### å‚æ•°è¯´æ˜
* `--base_model {base_model}` ï¼šå­˜æ”¾HFæ ¼å¼çš„Llama-3-Chinese-Instructæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚ä¹Ÿå¯ä½¿ç”¨ğŸ¤—Model Hubæ¨¡å‹è°ƒç”¨åç§°
* `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
* `--with_prompt`ï¼šæ˜¯å¦å°†è¾“å…¥ä¸promptæ¨¡ç‰ˆè¿›è¡Œåˆå¹¶ã€‚å¦‚æœåŠ è½½Llama-3-Chinese-instructæ¨¡å‹ï¼Œè¯·åŠ¡å¿…å¯ç”¨æ­¤é€‰é¡¹ï¼
* `--interactive`ï¼šä»¥äº¤äº’æ–¹å¼å¯åŠ¨ï¼Œä»¥ä¾¿è¿›è¡Œå¤šæ¬¡å•è½®é—®ç­”ï¼ˆæ­¤å¤„ä¸æ˜¯llama.cppä¸­çš„ä¸Šä¸‹æ–‡å¯¹è¯ï¼‰
* `--data_file {file_name}`ï¼šéäº¤äº’æ–¹å¼å¯åŠ¨ä¸‹ï¼ŒæŒ‰è¡Œè¯»å–file_nameä¸­çš„çš„å†…å®¹è¿›è¡Œé¢„æµ‹
* `--predictions_file {file_name}`ï¼šéäº¤äº’å¼æ–¹å¼ä¸‹ï¼Œå°†é¢„æµ‹çš„ç»“æœä»¥jsonæ ¼å¼å†™å…¥file_name
* `--only_cpu`ï¼šä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
* `--gpus {gpu_ids}`ï¼šæŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚0,1,2
* `--load_in_8bit`æˆ–`--load_in_4bit`ï¼šä½¿ç”¨8bitæˆ–4bitæ–¹å¼åŠ è½½æ¨¡å‹ï¼Œé™ä½æ˜¾å­˜å ç”¨ï¼Œæ¨èä½¿ç”¨--load_in_4bit
* `--use_vllm`ï¼šä½¿ç”¨vLLMä½œä¸ºLLMåç«¯è¿›è¡Œæ¨ç†
* `--use_flash_attention_2`: ä½¿ç”¨Flash-Attention 2åŠ é€Ÿæ¨ç†ï¼Œå¦‚æœä¸æŒ‡å®šè¯¥å‚æ•°ï¼Œä»£ç é»˜è®¤SDPAåŠ é€Ÿã€‚
è¯¥è„šæœ¬ä»…ä¸ºæ–¹ä¾¿å¿«é€Ÿä½“éªŒç”¨ï¼Œå¹¶æœªå¯¹æ¨ç†é€Ÿåº¦åšä¼˜åŒ–ã€‚

## 3.2ä½¿ç”¨llama.cppé‡åŒ–éƒ¨ç½²
ä»¥[llama.cpp](https://github.com/ggerganov/llama.cpp)å·¥å…·ä¸ºä¾‹ï¼Œä»‹ç»æ¨¡å‹é‡åŒ–å¹¶åœ¨æœ¬åœ°éƒ¨ç½²çš„è¯¦ç»†æ­¥éª¤ã€‚Windowsåˆ™å¯èƒ½éœ€è¦cmakeç­‰ç¼–è¯‘å·¥å…·çš„å®‰è£…ã€‚æœ¬åœ°å¿«é€Ÿéƒ¨ç½²ä½“éªŒæ¨èä½¿ç”¨ç»è¿‡æŒ‡ä»¤ç²¾è°ƒçš„Llama-3-Chinese-Instructæ¨¡å‹ï¼Œä½¿ç”¨6-bitæˆ–è€…8-bitæ¨¡å‹æ•ˆæœæ›´ä½³ã€‚ è¿è¡Œå‰è¯·ç¡®ä¿ï¼š
* 1.ç³»ç»Ÿåº”æœ‰makeï¼ˆMacOS/Linuxè‡ªå¸¦ï¼‰æˆ–cmakeï¼ˆWindowséœ€è‡ªè¡Œå®‰è£…ï¼‰ç¼–è¯‘å·¥å…·
* 2.å»ºè®®ä½¿ç”¨Python 3.10ä»¥ä¸Šç¼–è¯‘å’Œè¿è¡Œè¯¥å·¥å…·
#### Step 1: å…‹éš†å’Œç¼–è¯‘llama.cpp
#### llama.cppåœ¨2024å¹´4æœˆ30æ—¥å¯¹Llama-3 pre-tokenizeråšå‡ºé‡å¤§æ”¹åŠ¨ï¼ŒåŠ¡å¿…æ‹‰å–æœ€æ–°ä»£ç è¿›è¡Œç¼–è¯‘ï¼
* 1.æ‹‰å–æœ€æ–°ç‰ˆ`llama.cpp`ä»“åº“ä»£ç 
```
git clone https://github.com/ggerganov/llama.cpp
```
* 2.å¯¹`llama.cpp`é¡¹ç›®è¿›è¡Œç¼–è¯‘ï¼Œç”Ÿæˆ`./mainï¼ˆç”¨äºæ¨ç†ï¼‰`å’Œ`./quantize`ï¼ˆç”¨äºé‡åŒ–ï¼‰äºŒè¿›åˆ¶æ–‡ä»¶ã€‚
```
make
```
Windows/Linuxç”¨æˆ·å¦‚éœ€å¯ç”¨GPUæ¨ç†ï¼Œåˆ™æ¨èä¸[BLASï¼ˆæˆ–cuBLASå¦‚æœæœ‰GPUï¼‰ä¸€èµ·ç¼–è¯‘](https://github.com/ggerganov/llama.cpp#blas-build)ï¼Œå¯ä»¥æé«˜promptå¤„ç†é€Ÿåº¦ã€‚ä»¥ä¸‹æ˜¯å’ŒcuBLASä¸€èµ·ç¼–è¯‘çš„å‘½ä»¤ï¼Œé€‚ç”¨äºNVIDIAç›¸å…³GPUã€‚å‚è€ƒï¼š[llama.cpp#blas-build](https://github.com/ggerganov/llama.cpp#blas-build)
```
make LLAMA_CUDA=1
```
macOSç”¨æˆ·æ— éœ€é¢å¤–æ“ä½œï¼Œ`llama.cpp`å·²å¯¹ARM NEONåšä¼˜åŒ–ï¼Œå¹¶ä¸”å·²è‡ªåŠ¨å¯ç”¨BLASã€‚Mç³»åˆ—èŠ¯ç‰‡æ¨èä½¿ç”¨Metalå¯ç”¨GPUæ¨ç†ï¼Œæ˜¾è‘—æå‡é€Ÿåº¦ã€‚åªéœ€å°†ç¼–è¯‘å‘½ä»¤æ”¹ä¸ºï¼šLLAMA_METAL=1 makeï¼Œå‚è€ƒ[llama.cpp#metal-build](https://github.com/ggerganov/llama.cpp#metal-build)
```
LLAMA_METAL=1 make
```
#### Step 2: ç”Ÿæˆé‡åŒ–ç‰ˆæœ¬æ¨¡å‹
ä¹Ÿå¯ç›´æ¥ä¸‹è½½å·²é‡åŒ–å¥½çš„GGUFæ¨¡å‹ï¼š[ä¸‹è½½åœ°å€](#ä¸‹è½½åœ°å€)

ç›®å‰`llama.cpp`å·²æ”¯æŒ`.safetensors`æ–‡ä»¶ä»¥åŠ`Hugging Face`æ ¼å¼`.bin`è½¬æ¢ä¸ºFP16çš„`GGUF`æ ¼å¼ã€‚
$ python convert-hf-to-gguf.py llama-3-chinese-8b-instruct
$ ./quantize ggml-model-f16.gguf ggml-model-q4_0.gguf q4_0

#### Step 3: åŠ è½½å¹¶å¯åŠ¨æ¨¡å‹
ç”±äºæœ¬é¡¹ç›®æ¨å‡ºçš„Llama-3-Chinese-Instructä½¿ç”¨äº†åŸç‰ˆLlama-3-Instructçš„æŒ‡ä»¤æ¨¡æ¿ï¼Œè¯·é¦–å…ˆå°†æœ¬é¡¹ç›®çš„`scripts/llama_cpp/chat.sh`æ‹·è´è‡³`llama.cpp`çš„æ ¹ç›®å½•ã€‚`chat.sh`æ–‡ä»¶çš„å†…å®¹å¦‚ä¸‹æ‰€ç¤ºï¼Œå†…éƒ¨åµŒå¥—äº†èŠå¤©æ¨¡æ¿å’Œä¸€äº›é»˜è®¤å‚æ•°ï¼Œå¯æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œä¿®æ”¹ã€‚
* GPUæ¨ç†ï¼šcuBLAS/Metalç¼–è¯‘éœ€è¦æŒ‡å®šoffloadå±‚æ•°ï¼Œåœ¨./mainä¸­æŒ‡å®šä¾‹å¦‚-ngl 40è¡¨ç¤ºoffload 40å±‚æ¨¡å‹å‚æ•°åˆ°GPU
* ï¼ˆæ–°ï¼‰å¯ç”¨FlashAttentionï¼šå‘½ä»¤è¡Œä¸­æ·»åŠ -faå³å¯å¯ç”¨ï¼Œå¯åŠ é€Ÿæ¨ç†ï¼ˆå› è®¡ç®—è®¾å¤‡è€Œå¼‚ï¼‰
```
FIRST_INSTRUCTION=$2
SYSTEM_PROMPT="You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"

./main -m $1 --color -i \
-c 0 -t 6 --temp 0.2 --repeat_penalty 1.1 -ngl 999 \
-r '<|eot_id|>' \
--in-prefix '<|start_header_id|>user<|end_header_id|>\n\n' \
--in-suffix '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' \
-p "<|start_header_id|>system<|end_header_id|>\n\n$SYSTEM_PROMPT<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n$FIRST_INSTRUCTION<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"
```
ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨èŠå¤©ã€‚
```
chmod +x chat.sh
./chat.sh ggml-model-q4_0.gguf ä½ å¥½
```
åœ¨æç¤ºç¬¦ > ä¹‹åè¾“å…¥ä½ çš„promptï¼Œcmd/ctrl+cä¸­æ–­è¾“å‡ºï¼Œå¤šè¡Œä¿¡æ¯ä»¥\ä½œä¸ºè¡Œå°¾ã€‚å¦‚éœ€æŸ¥çœ‹å¸®åŠ©å’Œå‚æ•°è¯´æ˜ï¼Œè¯·æ‰§è¡Œ./main -hå‘½ä»¤ã€‚
æ›´è¯¦ç»†çš„å®˜æ–¹è¯´æ˜è¯·å‚è€ƒï¼š[https://github.com/ggerganov/llama.cpp/tree/master/examples/main](https://github.com/ggerganov/llama.cpp/tree/master/examples/main)

## 3.3ä½¿ç”¨ollamaéƒ¨ç½²
[Ollama](https://ollama.com/)æ˜¯ä¸€ä¸ªå¤šå¹³å°ï¼ˆmacOS, Windows, Linuxï¼‰çš„å¤§æ¨¡å‹èŠå¤©ç¨‹åºï¼Œèƒ½å¤ŸåŠ è½½GGUFæ ¼å¼ï¼ˆllama.cppï¼‰çš„æ¨¡å‹ã€‚æ¥ä¸‹æ¥å°†ç®€è¦ä»‹ç»ä½¿ç”¨æ–¹æ³•ã€‚å…¶ä½™ç”¨é€”è¯·è‡ªè¡Œå°è¯•å’ŒæŸ¥é˜…å®˜æ–¹æ‰‹å†Œè¿›è¡Œäº†è§£ã€‚

#### Step 1: ä¸‹è½½å¯¹åº”å¹³å°çš„åº”ç”¨ç¨‹åº
è¿›å…¥å®˜æ–¹é¡µé¢ä¸‹è½½å¯¹åº”å¹³å°çš„è½¯ä»¶ï¼šhttps://ollama.com/download
* âš ï¸ è¯·åŠ¡å¿…ä½¿ç”¨v0.1.33ä»¥ä¸Šç‰ˆæœ¬ï¼Œå¦åˆ™ä¼šå‡ºç°æ— é™ç”Ÿæˆçš„é—®é¢˜ã€‚
  ![image](https://github.com/user-wu/Chinese-llama3-fastdemo/assets/67259115/491bdcc2-98e3-4aad-817c-520e667ab794)
#### Step 2: å®‰è£…Ollama
* macOSï¼šä¸‹è½½å®Œæ¯•ä¹‹åç›´æ¥æ‹–å…¥â€œåº”ç”¨ç¨‹åºâ€
* Windows previewï¼šä¸‹è½½è¿è¡Œexeæ–‡ä»¶
* Linuxï¼šæ‰§è¡Œä»¥ä¸‹å‘½ä»¤
```
curl -fsSL https://ollama.com/install.sh | sh
```
å…¶ä½™å¹³å°è¯·å‚è€ƒï¼š[https://github.com/ollama/ollama?tab=readme-ov-file#ollama](https://github.com/ollama/ollama?tab=readme-ov-file#ollama)
#### Step 3ï¼šåˆ›å»ºModelfileæ–‡ä»¶
åœ¨æ–‡æœ¬ç¼–è¾‘å™¨ä¸­ç¼–å†™`Modelfile`æ–‡ä»¶ï¼Œå…¶å†…å®¹å¦‚ä¸‹ï¼š
```
FROM /your-path-to-ggml/ggml-model-q8_0.gguf
TEMPLATE """{{ if .System }}<|start_header_id|>system<|end_header_id|>

{{ .System }}<|eot_id|>{{ end }}{{ if .Prompt }}<|start_header_id|>user<|end_header_id|>

{{ .Prompt }}<|eot_id|>{{ end }}<|start_header_id|>assistant<|end_header_id|>

{{ .Response }}<|eot_id|>"""
SYSTEM """You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"""
PARAMETER temperature 0.2
PARAMETER num_keep 24
PARAMETER stop <|start_header_id|>
PARAMETER stop <|end_header_id|>
PARAMETER stop <|eot_id|>
```
å…¶ä¸­ï¼š

* `FROM`å­—æ®µæŒ‡å‘GGUFæ–‡ä»¶çš„è·¯å¾„ï¼Œç”±äºæ˜¯èŠå¤©äº¤äº’ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯Instructæ¨¡å‹
* `TEMPLATE`å­—æ®µå®šä¹‰äº†Llama-3-Instructçš„æŒ‡ä»¤æ¨¡æ¿æ ¼å¼
* `SYSTEM`å­—æ®µå®šä¹‰äº†ç³»ç»ŸæŒ‡ä»¤ï¼ˆç›®å‰è®¾ç½®ä¸ºç©ºï¼‰
* `PARAMETER`å­—æ®µå®šä¹‰äº†ä¸€äº›è¶…å‚æ•°ï¼Œè¯¦ç»†åˆ—è¡¨å‚è§ï¼š[https://github.com/ollama/ollama/blob/main/docs/modelfile.md](https://github.com/ollama/ollama/blob/main/docs/modelfile.md)

#### Step 4ï¼šåˆ›å»ºæ¨¡å‹å®ä¾‹
å‘½ä»¤è¡Œä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œåˆ›å»ºä¸€ä¸ªåä¸º`llama3-zh-inst`ï¼ˆåå­—å¯è‡ªå®šä¹‰ï¼‰çš„æ¨¡å‹å®ä¾‹ï¼ŒåŠ è½½`Modelfile`é…ç½®ï¼š
```
ollama create llama3-zh-inst -f Modelfile
```
åˆ›å»ºè¿‡ç¨‹è¾“å‡ºæ—¥å¿—å¦‚ä¸‹ï¼š
```
transferring model data
creating model layer
creating template layer
creating system layer
creating parameters layer
creating config layer
using already created layer sha256:f2a44c6358e8e0a60337f8a1b31f55f457558eeefd4f344272e44b0e73a86a32
using already created layer sha256:8ab4849b038cf0abc5b1c9b8ee1443dca6b93a045c2272180d985126eb40bf6f
writing layer sha256:b821abf159071cfc90f0941b5ca7ef721f229cfcfadcf95b5c58d0ceb3e773c7
writing layer sha256:dc4ec177268acc3382fc6c3a395e577bf13e9e0340dd313a75f62df95c48bc1d
writing manifest
success
```
è¾“å‡º`success`åï¼Œå³è¡¨ç¤ºå®Œæˆåˆ›å»ºã€‚
#### Step 5ï¼šå¼€å§‹èŠå¤©
è¾“å…¥ä»¥ä¸‹å‘½ä»¤è¿›å…¥èŠå¤©ç¨‹åº
```
ollama run llama3-zh-inst
```
åœ¨>>>åè¾“å…¥ç”¨æˆ·æŒ‡ä»¤ï¼›è¾“å…¥/byeç»“æŸèŠå¤©ã€‚

å…³äºollamaçš„å…¶ä»–ç”¨æ³•ï¼Œè¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼šhttps://github.com/ollama/ollama?tab=readme-ov-file#cli-reference

# å››ã€è®­ç»ƒä¸ç²¾è°ƒ

### è®­ç»ƒæ­¥éª¤
[è®­ç»ƒè„šæœ¬](./scripts/training/run_clm_pt_with_peft.py)

è¿›å…¥é¡¹ç›®çš„`scripts/training`ç›®å½•ï¼Œè¿è¡Œ`bash run_pt.sh`è¿›è¡ŒæŒ‡ä»¤ç²¾è°ƒï¼Œé»˜è®¤ä½¿ç”¨å•å¡ã€‚è¿è¡Œå‰ç”¨æˆ·åº”å…ˆä¿®æ”¹è„šæœ¬å¹¶æŒ‡å®šç›¸å…³å‚æ•°ï¼Œè„šæœ¬ä¸­çš„ç›¸å…³å‚æ•°å€¼ä»…ä¾›è°ƒè¯•å‚è€ƒã€‚`run_pt.sh`çš„å†…å®¹å¦‚ä¸‹ï¼š
```
########å‚æ•°è®¾ç½®########
lr=1e-4
lora_rank=64
lora_alpha=128
lora_trainable="q_proj,v_proj,k_proj,o_proj,gate_proj,down_proj,up_proj"
modules_to_save="embed_tokens,lm_head"
lora_dropout=0.05

pretrained_model=path/to/hf/meta-llama-3-8b/dir
dataset_dir=path/to/pt/data/dir
data_cache=temp_data_cache_dir
per_device_train_batch_size=1
gradient_accumulation_steps=8
block_size=1024
output_dir=output_dir

torchrun --nnodes 1 --nproc_per_node 1 run_clm_pt_with_peft.py \
    --model_name_or_path ${pretrained_model} \
    --tokenizer_name_or_path ${pretrained_model} \
    --dataset_dir ${dataset_dir} \
    --data_cache_dir ${data_cache} \
    --validation_split_percentage 0.001 \
    --per_device_train_batch_size ${per_device_train_batch_size} \
    --do_train \
    --seed $RANDOM \
    --bf16 \
    --num_train_epochs 1 \
    --lr_scheduler_type cosine \
    --learning_rate ${lr} \
    --warmup_ratio 0.05 \
    --weight_decay 0.1 \
    --logging_strategy steps \
    --logging_steps 10 \
    --save_strategy steps \
    --save_total_limit 3 \
    --save_steps 200 \
    --gradient_accumulation_steps ${gradient_accumulation_steps} \
    --preprocessing_num_workers 8 \
    --block_size ${block_size} \
    --output_dir ${output_dir} \
    --overwrite_output_dir \
    --ddp_timeout 30000 \
    --logging_first_step True \
    --lora_rank ${lora_rank} \
    --lora_alpha ${lora_alpha} \
    --trainable ${lora_trainable} \
    --lora_dropout ${lora_dropout} \
    --modules_to_save ${modules_to_save} \
    --torch_dtype bfloat16 \
    --load_in_kbits 16 \
    --ddp_find_unused_parameters False \
```

éƒ¨åˆ†å‚æ•°çš„è§£é‡Šå¦‚ä¸‹ï¼š

* `--dataset_dir`: é¢„è®­ç»ƒæ•°æ®çš„ç›®å½•ï¼Œå¯åŒ…å«å¤šä¸ªä»¥txtç»“å°¾çš„çº¯æ–‡æœ¬æ–‡ä»¶
* `--data_cache_dir`: æŒ‡å®šä¸€ä¸ªå­˜æ”¾æ•°æ®ç¼“å­˜æ–‡ä»¶çš„ç›®å½•
* `--use_flash_attention_2`: å¯ç”¨FlashAttention-2åŠ é€Ÿè®­ç»ƒ
* `--load_in_kbits`: å¯é€‰æ‹©å‚æ•°ä¸º16/8/4ï¼Œå³ä½¿ç”¨fp16æˆ–8bit/4bité‡åŒ–è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œé»˜è®¤bf16è®­ç»ƒã€‚
* `--modules_to_save`ï¼šéœ€è¦é¢å¤–è®­ç»ƒçš„æ¨¡å—ï¼Œæ³¨æ„è¿™éƒ¨åˆ†æ˜¯å…¨é‡ç²¾è°ƒï¼›èµ„æºå—é™çš„æƒ…å†µä¸‹è¯·è®¾ç½®ä¸ºNoneï¼ˆæ•ˆæœä¹Ÿä¼šå—åˆ°ä¸€äº›å½±å“ï¼‰
è¿™é‡Œåˆ—å‡ºçš„å…¶ä»–è®­ç»ƒç›¸å…³è¶…å‚æ•°ï¼Œå°¤å…¶æ˜¯å­¦ä¹ ç‡ä»¥åŠå’Œtotal batch sizeå¤§å°ç›¸å…³å‚æ•°ä»…ä¾›å‚è€ƒã€‚è¯·åœ¨å®é™…ä½¿ç”¨æ—¶æ ¹æ®æ•°æ®æƒ…å†µä»¥åŠç¡¬ä»¶æ¡ä»¶è¿›è¡Œé…ç½®ã€‚

### æŒ‡ä»¤æ¨¡æ¿

æœ¬é¡¹ç›®Llama-3-Chinese-Instructæ²¿ç”¨åŸç‰ˆLlama-3-Instructçš„æŒ‡ä»¤æ¨¡æ¿ã€‚ä»¥ä¸‹æ˜¯ä¸€ç»„å¯¹è¯ç¤ºä¾‹ï¼š

> <|begin_of_text|><|start_header_id|>system<|end_header_id|>
>
> You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚<|eot_id|><|start_header_id|>user<|end_header_id|>
>
> ä½ å¥½<|eot_id|><|start_header_id|>assistant<|end_header_id|>
>
> ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ<|eot_id|>

### æŒ‡ä»¤æ•°æ®

ä»¥ä¸‹æ˜¯æœ¬é¡¹ç›®å¼€æºçš„éƒ¨åˆ†æŒ‡ä»¤æ•°æ®ã€‚è¯¦æƒ…è¯·æŸ¥çœ‹ï¼š[ğŸ“š æŒ‡ä»¤æ•°æ®](./data)

# äº”ã€å…è´£å£°æ˜
æœ¬é¡¹ç›®åŸºäºç”±Metaå‘å¸ƒçš„Llama-3æ¨¡å‹è¿›è¡Œå¼€å‘ï¼Œä¾›å­¦ä¹ ä½¿ç”¨ã€‚ä½¿ç”¨è¿‡ç¨‹ä¸­è¯·ä¸¥æ ¼éµå®ˆLlama-3çš„[å¼€æºè®¸å¯åè®®](https://github.com/meta-llama/llama3/blob/main/LICENSE)ã€‚å¦‚æœæ¶‰åŠä½¿ç”¨ç¬¬ä¸‰æ–¹ä»£ç ï¼Œè¯·åŠ¡å¿…éµä»ç›¸å…³çš„å¼€æºè®¸å¯åè®®ã€‚æ¨¡å‹ç”Ÿæˆçš„å†…å®¹å¯èƒ½ä¼šå› ä¸ºè®¡ç®—æ–¹æ³•ã€éšæœºå› ç´ ä»¥åŠé‡åŒ–ç²¾åº¦æŸå¤±ç­‰å½±å“å…¶å‡†ç¡®æ€§ï¼Œå› æ­¤ï¼Œæœ¬é¡¹ç›®ä¸å¯¹æ¨¡å‹è¾“å‡ºçš„å‡†ç¡®æ€§æä¾›ä»»ä½•ä¿è¯ï¼Œä¹Ÿä¸ä¼šå¯¹ä»»ä½•å› ä½¿ç”¨ç›¸å…³èµ„æºå’Œè¾“å‡ºç»“æœäº§ç”Ÿçš„æŸå¤±æ‰¿æ‹…è´£ä»»ã€‚å¦‚æœå°†æœ¬é¡¹ç›®çš„ç›¸å…³æ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”ï¼Œå¼€å‘è€…åº”éµå®ˆå½“åœ°çš„æ³•å¾‹æ³•è§„ï¼Œç¡®ä¿æ¨¡å‹è¾“å‡ºå†…å®¹çš„åˆè§„æ€§ï¼Œæœ¬é¡¹ç›®ä¸å¯¹ä»»ä½•ç”±æ­¤è¡ç”Ÿçš„äº§å“æˆ–æœåŠ¡æ‰¿æ‹…è´£ä»»ã€‚

